# -*- coding: utf-8 -*-
"""MKCEClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i6zY9xDx0T7FUhk28hzghKZJCbsa2qK1
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
from sklearn import metrics
from sklearn.metrics import cohen_kappa_score, roc_auc_score, matthews_corrcoef
from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, classification_report,balanced_accuracy_score
df = pd.read_csv("/content/Thyroid.csv")

df.head()

df.info()

from sklearn.preprocessing import LabelEncoder

df['Gender']=df['Gender'].astype('category')
le=LabelEncoder()
df['Gender']=le.fit_transform(df['Gender'])

df['Smoking']=df['Smoking'].astype('category')
df['Smoking']=le.fit_transform(df['Smoking'])


df['Hx Smoking']=df['Hx Smoking'].astype('category')
df['Hx Smoking']=le.fit_transform(df['Hx Smoking'])

df['Hx Radiothreapy']=df['Hx Radiothreapy'].astype('category')
df['Hx Radiothreapy']=le.fit_transform(df['Hx Radiothreapy'])

df['Thyroid Function']=df['Thyroid Function'].astype('category')
df['Thyroid Function']=le.fit_transform(df['Thyroid Function'])


df['Physical Examination']=df['Physical Examination'].astype('category')
df['Physical Examination']=le.fit_transform(df['Physical Examination'])

df['Adenopathy']=df['Adenopathy'].astype('category')
df['Adenopathy']=le.fit_transform(df['Adenopathy'])

df['Pathology']=df['Pathology'].astype('category')
df['Pathology']=le.fit_transform(df['Pathology'])


df['Focality']=df['Focality'].astype('category')
df['Focality']=le.fit_transform(df['Focality'])

df['Risk']=df['Risk'].astype('category')
df['Risk']=le.fit_transform(df['Risk'])

df['T']=df['T'].astype('category')
df['T']=le.fit_transform(df['T'])


df['N']=df['N'].astype('category')
df['N']=le.fit_transform(df['N'])

df['M']=df['M'].astype('category')
df['M']=le.fit_transform(df['M'])

df['Stage']=df['Stage'].astype('category')
df['Stage']=le.fit_transform(df['Stage'])

df['Response']=df['Response'].astype('category')
df['Response']=le.fit_transform(df['Response'])

df['Recurred']=df['Recurred'].astype('category')
df['Recurred']=le.fit_transform(df['Recurred'])

df.info()

df.head()

df.rename(columns={'Hx Smoking': 'HxSmoke', 'Hx Radiothreapy': 'HxRadio','Thyroid Function': 'ThyroidFun', 'Physical Examination': 'PhyExam'}, inplace=True)

df.head()

import seaborn as sns

plt.figure(figsize=(12,10))
sns.heatmap(df.corr(),vmax=1, square=True, annot=True,cmap='coolwarm')
#plt.savefig('pearsoncorr', dpi=1080)

plt.figure(figsize=(12,10))
sns.pairplot(df,diag_kind = 'kde',
             plot_kws = {'edgecolor': 'k'}, size = 4)
plt.show()

df.hist(bins=50,figsize=(18,15))
#plt.savefig("histogram.png", dpi = 1080)
plt.show()

df.info()

dfper= pd.DataFrame(df, columns = df.columns)
dfper.drop(['PhyExam','Adenopathy','Focality','Risk'], axis=1, inplace=True)

"""**Separating Dependent and Independent Features**"""

y = dfper['Recurred'].copy()
X = pd.DataFrame(dfper, columns=dfper.columns)
X.drop(['Recurred'], axis=1, inplace=True)

dfper['Recurred'].value_counts()

plt.figure(figsize=(8,5))
sns.countplot(dfper,x='Recurred',palette="viridis_r")
plt.show()

plt.figure(figsize=(8,5))
sns.countplot(dfper,x='Recurred',stat="percent",palette="viridis_r")
plt.show()

"""**Split the dataset into two subsets: Training and Testing Data with Stratification**"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y,shuffle=True)

"""**Normalize the Dataset using Z-score Normalization**"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.neighbors import KNeighborsClassifier
classifier1=KNeighborsClassifier()
classifier1.fit(X_train,y_train)

y_pred1 = classifier1.predict(X_test)
conf_matrix = confusion_matrix(y_test, y_pred1,labels=[0,1])
acc_score = accuracy_score(y_test, y_pred1)
print("confusion matrix \n")
print( conf_matrix)
print("\n")
print(classification_report(y_test,y_pred1,labels=[0,1]))
print("\n")
tn, fp, fn, tp = confusion_matrix(y_test, y_pred1).ravel()
sensitivity= tp/(tp+fn)
print('Sensitivity :',sensitivity)
specificity = tn / (tn+fp)
print('Specificity :',specificity)
accuracy = (tn+tp) / (tn+fp+tp+fn)
print('Accuracy :',accuracy*100)
precision = tp / (tp+fp)
print('Precision :',precision)
f1 = (2*precision*sensitivity) / (precision+sensitivity)
print('F1 :',f1)
print("Kappa :",cohen_kappa_score(y_test, y_pred1))
auc = roc_auc_score(y_test,y_pred1)
print('AUC : %.3f' % auc)
print('MCCR :',matthews_corrcoef(y_test, y_pred1))

from sklearn.metrics import ConfusionMatrixDisplay

ConfusionMatrixDisplay.from_predictions(y_test, y_pred1, labels=[0,1],cmap='Blues')
plt.title('Confusion Matrix KNN')
plt.savefig('CMKNN.png', dpi = 1080)
plt.show()

"""**GRID SEARCH"""

from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
num_folds = 10
seed = 7
scoring = 'accuracy'

"""**KNN"""

k_values = np.array([1,3,5,7,9,11,13,15,17,19,21])
param_grid = dict(n_neighbors=k_values)
model = KNeighborsClassifier()
kfold = KFold(n_splits=3, random_state=42,shuffle=True)
grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)
grid_result = grid.fit(X_train, y_train)
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
  print("%f (%f) with: %r" % (mean, stdev, param))

model = KNeighborsClassifier(n_neighbors=3)
model.fit(X_train, y_train)
#Training Data
print("Training Results")
knnpredtr = model.predict(X_train)
conf_matrix = confusion_matrix(y_train,knnpredtr,labels=[0,1])
acc_score = accuracy_score(y_train,knnpredtr)
print('Accuracy :',acc_score*100)
print("confusion matrix \n")
print( conf_matrix)
print("\n")
print(classification_report(y_train,knnpredtr,labels=[0,1]))
print("\n")
#Testing Data
print("Testing Results")
knnpred = model.predict(X_test)
conf_matrix = confusion_matrix(y_test, knnpred,labels=[0,1])
acc_score = accuracy_score(y_test, knnpred)
print('Accuracy :',acc_score*100)
print("confusion matrix \n")
print( conf_matrix)
print("\n")
print(classification_report(y_test,knnpred,labels=[0,1]))
print("\n")

from sklearn.metrics import roc_curve, auc
from sklearn.metrics import roc_auc_score
Knnproba = classifier1.predict(X_test)
#Knnproba = Knnproba[:, 1]
Knnauc = roc_auc_score(y_test, Knnproba)
print('K-Nearest Neighbour: ROC AUC=%.3f' % (Knnauc))
fpr, tpr, _ = roc_curve(y_test, Knnproba)
# plot the roc curve for the KNN
plt.plot(fpr, tpr, marker='.',lw=1, color="darkorange",label='KNN (area = %0.3f)'%Knnauc)
plt.plot([0, 1], [0, 1],'-',color='black')
plt.xlabel('False Positive Rate (1-Specificity)')
plt.ylabel('True Positive Rate (Sensitivity)')
# show the legend
plt.legend()
# show the plot
plt.savefig('knnROC.png', dpi = 1080)
plt.show()

"""**SVM"""

from sklearn.svm import SVC

cval= np.array([1.0,1.5,2,3,3.5,4.0])
epsval=np.array([0.01,0.1,0.5,1.0,2.0])
#kernelval=['rbf','linear']
#kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1
param_grid = dict(C=cval,gamma=epsval)
model = SVC()
kfold = KFold(n_splits=3, random_state=42,shuffle=True)
grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)
grid_result = grid.fit(X_train, y_train)
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
  print("%f (%f) with: %r" % (mean, stdev, param))

svmmodel = SVC(C= 2.0, gamma=0.1, kernel= 'rbf',probability=True)
svmmodel.fit(X_train, y_train)
#Training Data
print("Training Results")
print("Training Results")
svmpredtr =svmmodel.predict(X_train)
conf_matrix = confusion_matrix(y_train,svmpredtr,labels=[0,1])
acc_score = accuracy_score(y_train,svmpredtr)
print('Accuracy :',acc_score*100)
print("confusion matrix \n")
print( conf_matrix)
print("\n")
print(classification_report(y_train,svmpredtr,labels=[0,1]))
print("\n")
#Testing Data
print("Testing Results")
svmpred = svmmodel.predict(X_test)
conf_matrix = confusion_matrix(y_test, svmpred,labels=[0,1])
acc_score = accuracy_score(y_test, svmpred)
print('Accuracy :',acc_score*100)
print("confusion matrix \n")
print( conf_matrix)
print("\n")
print(classification_report(y_test,svmpred,labels=[0,1]))
print("\n")

from sklearn.metrics import roc_curve, auc
from sklearn.metrics import roc_auc_score
svmproba = svmmodel.predict(X_test)
#Knnproba = Knnproba[:, 1]
svmauc = roc_auc_score(y_test, svmproba)
print('SVM: ROC AUC=%.3f' % (svmauc))
fpr, tpr, _ = roc_curve(y_test, svmproba)
# plot the roc curve for the KNN
plt.plot(fpr, tpr, marker='.',lw=1, color="darkorange",label='SVM (area = %0.3f)'%svmauc)
plt.plot([0, 1], [0, 1],'-',color='black')
plt.xlabel('False Positive Rate (1-Specificity)')
plt.ylabel('True Positive Rate (Sensitivity)')
# show the legend
plt.legend()
# show the plot
plt.savefig('SVMROC.png', dpi = 1080)
plt.show()

"""**RF"""

from sklearn.ensemble import RandomForestClassifier

param_grid = {
    'n_estimators': range(20, 100, 20),
    'max_depth': range(2, 10, 2),
    'min_samples_split': range(2, 10, 2),
    'max_features': ["auto", "sqrt", "log2"],
}

rfmodel= RandomForestClassifier(random_state=42)
kfold = KFold(n_splits=3, random_state=42,shuffle=True)
grid = GridSearchCV(estimator=rfmodel, param_grid=param_grid, scoring=scoring, cv=kfold)
grid_result = grid.fit(X_train, y_train)
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
  print("%f (%f) with: %r" % (mean, stdev, param))

rfmodel = RandomForestClassifier(max_depth=8,criterion='entropy',max_features='log2', min_samples_split=4, n_estimators= 40,random_state=1)
rfmodel.fit(X_train, y_train)
#Training Data
print("Training Results")
print("Training Results")
rfpredtr =rfmodel.predict(X_train)
conf_matrix = confusion_matrix(y_train,rfpredtr,labels=[0,1])
acc_score = accuracy_score(y_train,rfpredtr)
print('Accuracy :',acc_score*100)
print("confusion matrix \n")
print( conf_matrix)
print("\n")
print(classification_report(y_train,rfpredtr,labels=[0,1]))
print("\n")
#Testing Data
print("Testing Results")
rfpred = rfmodel.predict(X_test)
conf_matrix = confusion_matrix(y_test, rfpred,labels=[0,1])
acc_score = accuracy_score(y_test, rfpred)
print('Accuracy :',acc_score*100)
print("confusion matrix \n")
print( conf_matrix)
print("\n")
print(classification_report(y_test,rfpred,labels=[0,1]))
print("\n")
auc = roc_auc_score(y_test,rfpred)
print('AUC : %.3f' % auc)

ConfusionMatrixDisplay.from_predictions(y_test, rfpred, labels=[1,0],cmap='Blues')
plt.title('Confusion Matrix RF')
plt.savefig('CMRF.png', dpi = 1080)

#plt.savefig('CMKNN.png', dpi = 1080)
plt.show()

from sklearn.metrics import roc_curve, auc
from sklearn.metrics import roc_auc_score
rfproba = rfmodel.predict(X_test)
#Knnproba = Knnproba[:, 1]
rfauc = roc_auc_score(y_test, rfproba)
print('RF: ROC AUC=%.3f' % (rfauc))
fpr, tpr, _ = roc_curve(y_test, rfproba)
# plot the roc curve for the KNN
plt.plot(fpr, tpr, marker='.',lw=1, color="darkorange",label='RF (area = %0.3f)'%rfauc)
plt.plot([0, 1], [0, 1],'-',color='black')
plt.xlabel('False Positive Rate (1-Specificity)')
plt.ylabel('True Positive Rate (Sensitivity)')
# show the legend
plt.legend()
# show the plot
plt.savefig('RFROC.png', dpi = 1080)
plt.show()

from sklearn.metrics import roc_curve
from itertools import cycle

lines = ["--",":","-."]
linecycler = cycle(lines)
colors = cycle(['blue', 'red', 'green'])
colorcycler = cycle(colors)
for clas1, name1 in zip([model,svmmodel,rfmodel],
                      ['KNN','SVM','RF']):
    clas1.fit(X_train, y_train)
    accuracy=accuracy_score(y_test,clas1.predict(X_test))
    print('%s' % f"{name1}", accuracy)


    if hasattr(clas1, 'predict_proba'):
        # Compute False positive rate, and True positive rate
        fpr, tpr, thresholds = roc_curve(y_test, clas1.predict_proba(X_test)[:,1])
    else:
        # If predict_proba is not available, use decision_function instead
        fpr, tpr, thresholds = roc_curve(y_test, clas1.decision_function(X_test))

# Calculate Area under the curve to display on the plot
    auc = roc_auc_score(y_test,clas1.predict(X_test))
# Now, plot the computed values
    plt.plot(fpr, tpr, next(linecycler),lw=2, label='%s (area = %0.3f)' % (f"{name1}", auc))
# Custom settings for the plot
plt.plot([0, 1], [0, 1],'-',color='black')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic Curve')
plt.legend(loc="lower right")
plt.savefig("ROC", dpi = 1080)
plt.show()

"""**Cross Validation**"""

from sklearn.model_selection import StratifiedKFold, cross_val_score
skfolds = StratifiedKFold(n_splits=10,random_state=2,shuffle=True) #15
results=[]
clfname=[]
for clf, name1 in zip([model,svmmodel,rfmodel],
                      ['KNN','SVM','RF']):
  scores = cross_val_score(clf , X, y, cv = skfolds, scoring='accuracy')
  results.append(scores)
  clfname.append(name1)
  print("%s Cross Validation Accuracy: %.3f" %(name1,scores.mean()))
  scores = cross_val_score(clf , X, y, cv = skfolds, scoring='precision')
  results.append(scores)
  clfname.append(name1)
  print("%s Cross Validation precision: %.3f" %(name1,scores.mean()))
  scores = cross_val_score(clf , X, y, cv = skfolds, scoring='recall')
  results.append(scores)
  clfname.append(name1)
  print("%s Cross Validation recall: %.3f" %(name1,scores.mean()))
  scores = cross_val_score(clf , X, y, cv = skfolds, scoring='f1')
  results.append(scores)
  clfname.append(name1)
  print("%s Cross Validation f1: %.3f" %(name1,scores.mean()))
  print("\n")
  #print("Average CV Accuracy: ", scores.mean())